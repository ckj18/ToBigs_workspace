{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ckj18/ToBigs_workspace/blob/main/Week1_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJp8TJCC42ji"
      },
      "source": [
        "# Week1_Library 과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTmELSqe42jo"
      },
      "source": [
        "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVQYf7od42jo"
      },
      "source": [
        "라이브러리는 일종의 도구로 개발의 툴인 프레임워크와 달리 제약없이 자유롭게 사용이 가능하지만, 프레임워크는 메뉴얼에 따라 프로그램을 만든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiBO4WlX42jp"
      },
      "source": [
        "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKoqe0U542jp"
      },
      "source": [
        "딥러닝은 머신러닝에 속해 있으며, 머신러닝은 컴퓨터가 스스로 학습하여 AI 성능을 향상시키는 기술이고 딥러닝은 인간의 뉴런과 비슷한 인공신경망 방식으로 정보를 처리하는 것이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mVGrI3U42jp"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "updrldkQ42jq"
      },
      "source": [
        "### Q3. 아래의 코드에 주석 달기."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLlaXiMj42jq"
      },
      "outputs": [],
      "source": [
        "## 한 GPU에만 Cuda 연산을 할당하기 위해 사용 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED_Y0c6Y42js"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transfroms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "torch.manual_seed(45)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(45)\n",
        "print(device + \" is available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwK-n6e842ju"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxOWQ7MU42ju"
      },
      "outputs": [],
      "source": [
        "## MNIST 데이터 셋에서 train set과 test set을 지정하고 transformer를 통해 텐서로 변환\n",
        "train_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor() \n",
        "    ])\n",
        ")\n",
        "\n",
        "test_set = torchvision.datasets.MNIST(\n",
        "    root = './data/MNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transfroms.Compose([\n",
        "        transfroms.ToTensor()\n",
        "    ])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ORdyRS42jv"
      },
      "outputs": [],
      "source": [
        "## batch_size는 100, 데이터 셋에서 batch를 통해 100개씩 묶어 파라미터를 업데이트 \n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
        "\n",
        "examples = enumerate(train_set)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "example_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LboqfmR42jv"
      },
      "outputs": [],
      "source": [
        "## 학습에 사용되는 모델로, 사용되는 layer function은 init에 정의되어 있으며, forward를 통해 layer 층을 구성\n",
        "## Conv -> MaxPool -> ReLu -> Conv -> MaxPool -> ReLu -> DropOut -> Flatten -> fc -> fc -> log_softmax의 순서로 진행\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self): \n",
        "        super(ConvNet, self).__init__() \n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) \n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) \n",
        "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False) \n",
        "        self.mp = nn.MaxPool2d(2)\n",
        "        self.fc1 = nn.Linear(320,100) \n",
        "        self.fc2 = nn.Linear(100,10) \n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = F.relu(self.mp(self.conv1(x))) \n",
        "        x = F.relu(self.mp(self.conv2(x))) \n",
        "        x = self.drop2D(x) \n",
        "        x = x.view(x.size(0), -1) \n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlnISPkL42jw"
      },
      "outputs": [],
      "source": [
        "## ConvNet 모델과 CrossEntropyLoss를 사용하고 Optimizer로 Adam, lr=0.001로 지정\n",
        "model = ConvNet().to(device) \n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXib-GTC42jw"
      },
      "outputs": [],
      "source": [
        "## 5번의 반복 학습을 하며, 모델을 통해 학습한 예측값 hypothesis와 정답 label인 target 값의 loss를 구하고 최적화를 통해 진행\n",
        "for epoch in range(epochs): \n",
        "    avg_cost = 0\n",
        "    for data, target in train_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad() \n",
        "        hypothesis = model(data)\n",
        "        cost = criterion(hypothesis, target) \n",
        "        cost.backward()\n",
        "        optimizer.step() \n",
        "        avg_cost += cost / len(train_loader) \n",
        "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wHCJqpj42jx"
      },
      "outputs": [],
      "source": [
        "## test에는 no_grad()를 사용해야 하며, train에서 학습된 모델로, 예측값 preds와 정답 label target 값이 일치하는 correct의 비율을 계산 \n",
        "model.eval()\n",
        "with torch.no_grad(): \n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "        out = model(data)\n",
        "        preds = torch.max(out.data, 1)[1] \n",
        "        total += len(target) \n",
        "        correct += (preds==target).sum().item() \n",
        "        \n",
        "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92DjV5A742jx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haeWwQ7D42jx"
      },
      "source": [
        "## 첫 정규세션 들으시느라 고생 많으셨습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGzAKR6U42jx"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c8758ede8fb5b1b22b6571a5c50167e14022fbbcb9edb3d484f2c2c206d32150"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}